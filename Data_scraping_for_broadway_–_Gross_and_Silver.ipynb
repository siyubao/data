{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data scraping for broadway â€“ Gross and Silver.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siyubao/data/blob/master/Data_scraping_for_broadway_%E2%80%93_Gross_and_Silver.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKGqVuL5PghD",
        "colab_type": "text"
      },
      "source": [
        "# Scraping Broadway Data\n",
        "## By Yaakov Bressler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nv1f_aA0QXJ0",
        "colab_type": "text"
      },
      "source": [
        "Functions herein provide a means of scraping **\"Gross\"** and **\"Silver\"** Broadway data.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Broadway Gross Data Contains:**\n",
        "*   Show Name\n",
        "*   Date (describing Week)\n",
        "*   Week Number\n",
        "*   Gross ($)\n",
        "*   Gross Difference (From Week Prior)\n",
        "\n",
        "*   Gross Potential italicized text ($)\n",
        "*   Gross  Potential (%)\n",
        "*   Average Ticket Price\n",
        "*   Top Ticket Price\n",
        "*   Seats Sold\n",
        "*   Seats Available\n",
        "*   Number of Performances\n",
        "*   Capacity (%)\n",
        "*   Capacity Difference (From Week Prior)\n",
        "\n",
        "\n",
        "**Broadway Silver Data Contains: **\n",
        "*   Show Name\n",
        "*   Show Type\n",
        "*   Theatre Name\n",
        "*   Theatre Address\n",
        "*   Production Type\n",
        "*   Run Type\n",
        "*   Market\n",
        "*   Intermission\n",
        "*   Run Time\n",
        "*   Date Previews\n",
        "*   Date Opening\n",
        "*   Date Closing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XGB29LKPghE",
        "colab_type": "text"
      },
      "source": [
        "### Create a function that grabs links from a page, using a tag to identify value of link"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpOVWbZ-PghF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import urllib.request\n",
        "import re\n",
        "\n",
        "def getLinks_tagged_fast(url, tag):\n",
        "    r = requests.get(url)\n",
        "    html_doc = r.text\n",
        "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
        "    links = []\n",
        "    # set the opening of each link to be...\n",
        "    tag = tag\n",
        "    for link in soup.findAll('a', attrs={'href': re.compile(tag)}):\n",
        "        links.append(link.get('href'))\n",
        "    return links"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoG4VIQqPghI",
        "colab_type": "text"
      },
      "source": [
        "# Scrape Gross Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRzcyQ-JPghJ",
        "colab_type": "text"
      },
      "source": [
        "Create function that gets pages to loop in get data function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zDSSD-6PghK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "import time\n",
        "import re\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import urllib\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import datetime\n",
        "\n",
        "def get_gross_pages(url_base):\n",
        "    page_base = url_base\n",
        "    abc = list(string.ascii_lowercase)\n",
        "    abc.append('1')\n",
        "    list_loop_az =[]\n",
        "    for a in abc:\n",
        "        list_loop_az.append(page_base+a)\n",
        "    \n",
        "    #Congrats, you have list_loop_az, pages a - z where all the shows are contained\n",
        "    \n",
        "    # Now, write a code that gets all the links:\n",
        "    def getLinks_tagged(url, tag):\n",
        "        r = requests.get(url)\n",
        "        html_doc = r.text\n",
        "        soup = BeautifulSoup(html_doc, 'html.parser')\n",
        "        links = []\n",
        "        # set the opening of each link to be...\n",
        "        tag = tag\n",
        "        for link in soup.findAll('a', attrs={'href': re.compile(tag)}):\n",
        "            links.append(link.get('href'))\n",
        "        return links\n",
        "\n",
        "    # Now use the function:\n",
        "    show_links_nested = []\n",
        "    tag = 'https://www.broadwayworld.com/grosses/'\n",
        "    for page in list_loop_az:\n",
        "        show_links_nested.append(getLinks_tagged(page, tag))\n",
        "    show_links = sum(show_links_nested, [])\n",
        "    \n",
        "    #Congrats, you have show_links, pages where all the shows are contained\n",
        "    \n",
        "    # Now, write a code that gets all the content:\n",
        "    def get_gross(urls):\n",
        "        # column names\n",
        "        dfs = []\n",
        "        cols = ['Week','Week_Numer', 'Gross', 'Gross_Diff', 'Pot_Gross',\n",
        "                'Potential_Gross_Percent','Average_Paid_Ticket', 'Top_Ticket','Seats_Sold',\n",
        "                'Total_Seats', 'Performances','Capacity', 'Capacity_Diff']\n",
        "        for url in urls:\n",
        "            df = pd.read_html(url)[0]\n",
        "            df = df.drop([0,1,2,3])\n",
        "            df = df.dropna(how='all')\n",
        "            df = df.drop(df.index[0])\n",
        "            df = df.dropna(thresh = .01 * len(df), axis=1)\n",
        "            df.columns = cols\n",
        "            df['Show_Name'] = re.split('^https://www.broadwayworld.com/grosses/*', url)[1].replace(\"-\", \" \").title()\n",
        "            df = df[:-3]\n",
        "            dfs.append(df)\n",
        "        finaldf = pd.concat(dfs) \n",
        "        return finaldf\n",
        "    \n",
        "    broadway = get_gross(show_links)\n",
        "    \n",
        "    \n",
        "    # Save the df\n",
        "    today = datetime.date.today().strftime('%m-%d-%Y') \n",
        "    output_file = 'broadway_grosses {}.csv'.format(today)\n",
        "    broadway.to_csv(output_file)\n",
        "    \n",
        "    return broadway"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lx4Js5L_PghO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "broadway = get_gross_pages('https://www.broadwayworld.com/grossesbyshow.cfm?letter=')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIlhED4GPghQ",
        "colab_type": "text"
      },
      "source": [
        "# Get Show Links through Theatre URLS\n",
        "(Doesn't provide full list of shows, so don't use...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGhvNqisPghQ",
        "colab_type": "text"
      },
      "source": [
        "This link is your starting point:\n",
        "\n",
        "https://www.broadwayworld.com/industry-bww-theatres.cfm\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aU0dhDnPghS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import urllib\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import urllib.request\n",
        "from inscriptis import get_text\n",
        "\n",
        "def get_show_link_lists(theatre_url):\n",
        "#################################################\n",
        "    def getLinks_tagged_fast(url, tag):\n",
        "        r = requests.get(url)\n",
        "        html_doc = r.text\n",
        "        soup = BeautifulSoup(html_doc, 'html.parser')\n",
        "        links = []\n",
        "         # set the opening of each link to be...\n",
        "        tag = tag\n",
        "        for link in soup.findAll('a', attrs={'href': re.compile(tag)}):\n",
        "            links.append(link.get('href'))\n",
        "        return links\n",
        "        \n",
        "#################################################\n",
        "\n",
        "    url_foo = theatre_url\n",
        "\n",
        "    tag_theatre = 'https://www.broadwayworld.com/shows/theatre'\n",
        "    tag_show = '/shows/'\n",
        "    theatres = getLinks_tagged_fast(url_foo, tag_theatre)\n",
        "    show_links_nested = []\n",
        "    for theatre in theatres:\n",
        "        show_links_nested.append(getLinks_tagged_fast(theatre, tag_show))\n",
        "    \n",
        "    show_links = sum(show_links_nested, [])\n",
        "    show_links = [link for link in show_links if not link.startswith('/shows/shows')]\n",
        "    page_base = 'https://www.broadwayworld.com'\n",
        "    show_list_loop =[]\n",
        "    for show in show_links:\n",
        "        show_list_loop.append(page_base+show)\n",
        "    show_links_production = sum(show_links_nested, [])\n",
        "    show_links_production = [link for link in show_links if not link.startswith('/shows/shows')]\n",
        "\n",
        "    show_links_nums_pre = []\n",
        "    show_links_nums = []\n",
        "\n",
        "    for link in show_links_production:\n",
        "        show_links_nums_pre.append(re.findall('\\d+\\.', link))\n",
        "    show_links_nums_pre = sum(show_links_nums_pre, [])\n",
        "\n",
        "    for link in show_links_nums_pre:\n",
        "        show_links_nums.append(re.findall('\\d+', link))\n",
        "    show_links_nums = sum(show_links_nums, [])\n",
        "\n",
        "    prod_info_base = 'https://www.broadwayworld.com/shows/backstage.php?showid='\n",
        "    cast_base = 'https://www.broadwayworld.com/shows/cast.php?showid='\n",
        "\n",
        "    prod_info_show_loop =[]\n",
        "    for show in show_links_nums:\n",
        "        prod_info_show_loop.append(prod_info_base+show)\n",
        "\n",
        "    cast_show_loop =[]\n",
        "    for show in show_links_nums:\n",
        "        cast_show_loop.append(cast_base+show)\n",
        "    \n",
        "    return[prod_info_show_loop,cast_show_loop]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr7kULh5PghU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# will give you a list of two lists....\n",
        "# First list is for silver function\n",
        "# Second list is for bronze function\n",
        "\n",
        "url = 'https://www.broadwayworld.com/industry-bww-theatres.cfm'\n",
        "show_links = get_show_link_lists(url)\n",
        "print('The list \\'show_links\\' contains a total of %d shows' %len(show_links[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p23CaALFPghX",
        "colab_type": "text"
      },
      "source": [
        "# Get links through Years URLS\n",
        "** This works, so indeed use.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YW_M9CqNPghX",
        "colab_type": "text"
      },
      "source": [
        "This link is your starting point:\n",
        "\n",
        "https://www.broadwayworld.com/browseshows.cfm?showtype=BR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FksN-agPghY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import urllib.request\n",
        "from inscriptis import get_text\n",
        "\n",
        "def get_show_links_year(year_url):\n",
        "    \n",
        "#################################################\n",
        "    def getLinks_tagged_fast(url2, tag):\n",
        "        r = requests.get(url2)\n",
        "        html_doc = r.text\n",
        "        soup = BeautifulSoup(html_doc, 'html.parser')\n",
        "        links = []\n",
        "         # set the opening of each link to be...\n",
        "        tag = tag\n",
        "        for link in soup.findAll('a', attrs={'href': re.compile(tag)}):\n",
        "            links.append(link.get('href'))\n",
        "        return links\n",
        "        \n",
        "#################################################\n",
        "\n",
        "    url = year_url\n",
        "    tag_year = 'browseshows.cfm?'\n",
        "    years = getLinks_tagged_fast(url, tag_year)[1:]\n",
        "    page_base = 'https://www.broadwayworld.com/'\n",
        "    years_loop =[]\n",
        "    for year in years:\n",
        "        years_loop.append(page_base+year)\n",
        "\n",
        "    # Now you have all the years..\n",
        "    tag_show = 'https://www.broadwayworld.com/shows/backstage.php?'\n",
        "    show_links_nested = []\n",
        "    for year in years_loop:\n",
        "        show_links_nested.append(getLinks_tagged_fast(year,tag_show))\n",
        "    show_links = sum(show_links_nested, [])\n",
        "    \n",
        "    cast_links =[]\n",
        "    #Get all the cast info:\n",
        "    for link in show_links:\n",
        "        cast_links.append(link.replace('backstage', 'cast'))\n",
        "        \n",
        "    # Now you have all the productions...\n",
        "    creative_links =[]\n",
        "    #Get all the cast info:\n",
        "    for link in show_links:\n",
        "        creative_links.append(link.replace('backstage', 'creative'))\n",
        "        \n",
        "\n",
        "    return[show_links,cast_links,creative_links]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wugFbJIJPghb",
        "colab_type": "code",
        "outputId": "846dfb3d-5fac-4c24-e0c8-6d8d973fa140",
        "colab": {}
      },
      "source": [
        "# will give you a list of two lists....\n",
        "# First list is for silver function (show production information)\n",
        "# Second list is for bronze function (function not yet devised, will be for Awards and such)\n",
        "\n",
        "year_url = 'https://www.broadwayworld.com/browseshows.cfm?showtype=BR'\n",
        "show_links_nested = get_show_links_year(year_url)\n",
        "print('The list \\'show_links_nested\\' contains a total of %d shows' %len(show_links_nested[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The list 'show_links_nested' contains a total of 13568 shows\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mWrgBB_Pghj",
        "colab_type": "code",
        "outputId": "d4adad4c-2bd3-4a04-aca9-9219453ee529",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "show_links_df_pre = pd.DataFrame(show_links_nested)\n",
        "show_links_df = show_links_df_pre.transpose()\n",
        "show_links_df.columns=['show_links','cast_links','creative_links']\n",
        "show_links_df.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 13568 entries, 0 to 13567\n",
            "Data columns (total 3 columns):\n",
            "show_links        13568 non-null object\n",
            "cast_links        13568 non-null object\n",
            "creative_links    13568 non-null object\n",
            "dtypes: object(3)\n",
            "memory usage: 318.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ83TQMbPghm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "today = datetime.date.today().strftime('%m-%d-%Y') \n",
        "show_links_df.to_csv('show_links_df {}.csv'.format(today))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amFMPNNcPghs",
        "colab_type": "text"
      },
      "source": [
        "----\n",
        "\n",
        "### Import your spreadsheet with show links:\n",
        "\n",
        "*Better to download the list of shows then upload and continue working, if your kernel freezes and you have to start again, this will save lots of time.*\n",
        "\n",
        "----\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-U_HwY0Pght",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "path = os.getcwd()\n",
        "csvfile = '/show_links_df 09-06-2018.csv'\n",
        "file = (path+csvfile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOqID-PmPghw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_links_df = pd.read_csv(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR8yLZSOPgh0",
        "colab_type": "code",
        "outputId": "b2cfc983-e8ae-428b-bdc8-5f69e75f1a12",
        "colab": {}
      },
      "source": [
        "show_links_df.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 13568 entries, 0 to 13567\n",
            "Data columns (total 4 columns):\n",
            "Unnamed: 0        13568 non-null int64\n",
            "show_links        13568 non-null object\n",
            "cast_links        13568 non-null object\n",
            "creative_links    13568 non-null object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 424.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7skFDP65Pgh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_links = show_links_df['show_links'].tolist()\n",
        "cast_links = show_links_df['cast_links'].tolist()\n",
        "creative_links = show_links_df['creative_links'].tolist()\n",
        "show_links_nested = [show_links,cast_links,creative_links]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEHpTQaEPgh6",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "url = 'https://www.broadwayworld.com/browseshows.cfm?showtype=BR'\n",
        "\n",
        "Applying **show_links_nested** function on the above url results in a list of lists of shows:\n",
        "    \n",
        "    show_links_nested\n",
        "    \n",
        "List 0 is show production info, list 1 is cast info\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hF1NNW4zPgh8",
        "colab_type": "text"
      },
      "source": [
        "# Scrape Silver data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhBUCF7lPgh9",
        "colab_type": "text"
      },
      "source": [
        "### Pre functions that will be built into the main function\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyI7zC4-Pgh9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get Visible text\n",
        "from bs4 import BeautifulSoup\n",
        "from bs4.element import Comment\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def tag_visible(element):\n",
        "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
        "        return False\n",
        "    if isinstance(element, Comment):\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "def text_from_html(body):\n",
        "    soup = BeautifulSoup(body, 'html.parser')\n",
        "    texts = soup.findAll(text=True)\n",
        "    visible_texts = filter(tag_visible, texts)  \n",
        "    return u\" \".join(t.strip() for t in visible_texts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNW_KqgbPgh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YB: This function is a bit sloppy and could be cleaned, but it works.\n",
        "\n",
        "def text_to_nums_str(input_text_1):\n",
        "    output_words = []\n",
        "    num_dic={'One':'1','Two':'2','Three':'3','Four':'4','Five':'5',\n",
        "             'Six':'6','Seven':'7','Eight':'8','Nine':'9',\n",
        "             'one':'1', 'two':'2','three':'3','four':'4', 'no':'0', 'No':'0','None':'0','none':'0'}\n",
        "   \n",
        "    if pd.notnull(input_text_1) is True:\n",
        "        for word in input_text_1.split():\n",
        "            output_word = \"\".join(str(x) for x in(re.sub(r'\\b\\w+\\b',lambda m: num_dic.get(m.group(), m.group()) , word)))\n",
        "            output_words.append(output_word)\n",
        "        output_words = \" \".join(str(x) for x in output_words)\n",
        "    else:\n",
        "        output_words = np.NaN\n",
        "    return output_words\n",
        "\n",
        "def show_runs_text_to_nums_str(input_text_1):\n",
        "    output_words = []\n",
        "    num_dic={'One':'1','Two':'2','Three':'3','Four':'4','Five':'5', 'Six':'6',\n",
        "             'Seven':'7','Eight':'8','Nine':'9','one':'1', 'two':'2','three':'3',\n",
        "             'four':'4', 'no':'0', 'No':'0','None':'0','none':'0'}\n",
        "    #num_dic_pair={'hours, with':'00','hours with':'00','hours\\nwith':'00','hours\\n with':'00'} \n",
        "   \n",
        "    if pd.notnull(input_text_1) is True:\n",
        "        for word in input_text_1.split():\n",
        "            output_word = \"\".join(str(x) for x in(re.sub(r'\\b\\w+\\b',lambda m: num_dic.get(m.group(), m.group()) , word)))\n",
        "            #output_word = \"\".join(str(x) for x in(re.sub(r'\\b\\w+\\s\\w+\\b',lambda m: num_dic_pair.get(m.group(), m.group()) , output_word_pre)))\n",
        "            output_words.append(output_word)\n",
        "        output_words = \" \".join(str(x) for x in output_words)\n",
        "    else:\n",
        "        output_words = np.NaN\n",
        "    return output_words\n",
        "    \n",
        "# An alternative in lambda:\n",
        "#output_text = \" \".join(str(x) for x in([re.sub(r'\\b\\w+\\b',lambda m: num_dic.get(m.group(), m.group()) , s) for s in text.split()]))\n",
        "\n",
        "def get_minutes_no_intermission(input_text_2):\n",
        "    z = show_runs_text_to_nums_str(input_text_2)\n",
        "    if pd.notnull(z) is True:\n",
        "        run_time = re.findall('\\d', z)\n",
        "        if len(run_time) >= 1:\n",
        "            if len(run_time) >=2:\n",
        "                if len(run_time) >= 3:\n",
        "                    minutes = int(run_time[1]+run_time[2])\n",
        "                    hour = (int(run_time[0])*60)\n",
        "                else:\n",
        "                    minutes = int(run_time[0]+run_time[1])\n",
        "                    hour = 0\n",
        "            else:\n",
        "                minutes = int(run_time[0])\n",
        "                hour = 0\n",
        "        else:\n",
        "            minutes = 0\n",
        "            hour = 0 \n",
        "        run_time_pre = hour+minutes\n",
        "       \n",
        "    #the code below doesn't do what I want it to do.\n",
        "        if run_time_pre >0:\n",
        "            if run_time_pre ==4:\n",
        "                run_time = 240\n",
        "            if run_time_pre ==3:\n",
        "                run_time = 180\n",
        "            if run_time_pre ==2:\n",
        "                run_time = 120\n",
        "            if run_time_pre ==1:\n",
        "                run_time = 60\n",
        "            else:    \n",
        "                run_time = run_time_pre\n",
        "        else:\n",
        "            run_time = np.NaN\n",
        "    else:\n",
        "        run_time = np.NaN    \n",
        "    return run_time\n",
        "\n",
        "\n",
        "\n",
        "def get_minutes_yes_intermission(input_text_2):\n",
        "    z = show_runs_text_to_nums_str(input_text_2)\n",
        "    if pd.notnull(z) is True:\n",
        "        run_time = re.findall('\\d', z)\n",
        "        if len(run_time) >= 2:\n",
        "            if len(run_time) >=3:\n",
        "                if len(run_time) >= 4:\n",
        "                    minutes = int(run_time[1]+run_time[2])\n",
        "                    hour = (int(run_time[0])*60)\n",
        "                else:\n",
        "                    minutes = int(run_time[0]+run_time[1])\n",
        "                    hour = 0\n",
        "            else:\n",
        "                minutes = int(run_time[0])\n",
        "                hour = 0\n",
        "        else:\n",
        "            minutes = 0\n",
        "            hour = 0 \n",
        "        run_time_pre = hour+minutes\n",
        "        #the code below doesn't do what I want it to do.\n",
        "        if run_time_pre >0:\n",
        "            if run_time_pre ==4.0:\n",
        "                run_time == 240\n",
        "            if run_time_pre ==3.0:\n",
        "                run_time = 180\n",
        "            if run_time_pre ==2.0:\n",
        "                run_time = 120\n",
        "            if run_time_pre ==1.0:\n",
        "                run_time = 60\n",
        "            else:    \n",
        "                run_time = run_time_pre\n",
        "        else:\n",
        "            run_time = np.NaN\n",
        "    else:\n",
        "        run_time = np.NaN   \n",
        "    \n",
        "    return run_time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0DLM57UPgiF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If you want a progress bar in the silver function\n",
        "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = 'â–ˆ'):\n",
        "    \"\"\"\n",
        "    Call in a loop to create terminal progress bar\n",
        "    @params:\n",
        "        iteration   - Required  : current iteration (Int)\n",
        "        total       - Required  : total iterations (Int)\n",
        "        prefix      - Optional  : prefix string (Str)\n",
        "        suffix      - Optional  : suffix string (Str)\n",
        "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
        "        length      - Optional  : character length of bar (Int)\n",
        "        fill        - Optional  : bar fill character (Str)\n",
        "    \"\"\"\n",
        "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
        "    filledLength = int(length * iteration // total)\n",
        "    bar = fill * filledLength + '-' * (length - filledLength)\n",
        "    print('\\r%s |%s| %s%% %s' % (prefix, bar, percent, suffix), end = '\\r')\n",
        "    # Print New Line on Complete\n",
        "    if iteration == total: \n",
        "        print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0WFv04rPgiH",
        "colab_type": "code",
        "outputId": "946eb42c-6655-4eea-ae35-757148d921d4",
        "colab": {}
      },
      "source": [
        "# Test the progress bar\n",
        "\n",
        "from time import sleep\n",
        "import sys\n",
        "\n",
        "items = list(range(0, len(show_links_nested[0])))\n",
        "l = len(items)\n",
        "\n",
        "# Initial call to print 0% progress\n",
        "printProgressBar(0, l, prefix = 'Progress:', suffix = 'Complete', length = 70)\n",
        "for i, item in enumerate(items):\n",
        "    sys.stdout.write(\"-\") # prints a dash for each iteration of loop\n",
        "    sys.stdout.flush() # ensures bar is displayed incrementally\n",
        "    # Do stuff...\n",
        "    sleep(0.00001)\n",
        "    # Update Progress Bar\n",
        "    printProgressBar(i + 1, l, prefix = 'Progress:', suffix = 'Complete', length = 50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete---| 0.0% Complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCSc9HQ1PgiL",
        "colab_type": "text"
      },
      "source": [
        "### Actual function\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVY03UDMPgiM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Utilize function to get silver data from websites using text parsing...\n",
        "import string\n",
        "import time\n",
        "import re\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests as req\n",
        "import urllib.request\n",
        "from bs4 import BeautifulSoup\n",
        "import datetime   \n",
        "from termcolor import colored\n",
        "import sys\n",
        "from termcolor import colored, cprint\n",
        "\n",
        "def get_silver_data(silver_urls):\n",
        "    # for progress bar\n",
        "    l = len(silver_urls)\n",
        "    dfs_silver_list = []\n",
        "    start = time.time()\n",
        "    # for enumerating progress + errors\n",
        "    n=0\n",
        "    n_i = n\n",
        "    lost_rows = 0\n",
        "    for each_silver_url in silver_urls:\n",
        "        print('\\n')\n",
        "        \n",
        "        # Next three lines print progress bar. Omit if you don't want.\n",
        "        sys.stdout.write(\"-\") # prints a dash for each iteration of loop\n",
        "        sys.stdout.flush() # ensures bar is displayed incrementally\n",
        "        printProgressBar(n + 1, l, prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
        "        \n",
        "        # Prints which line is being downloaded, helpful if there is an error.\n",
        "        print('\\n\\n%d line is being downloaded' %n)\n",
        "        \n",
        "        # ML logic:\n",
        "        try:\n",
        "            html = urllib.request.urlopen(each_silver_url).read()\n",
        "            text = text_from_html(html)\n",
        "            text2 = re.sub(' +',' ',text)\n",
        "            if 'Update BWW\\'s Database ' in text2:\n",
        "                text3 = text.split('Update BWW\\'s Database ')[1]\n",
        "            if 'SHOW TYPE:' in text3:\n",
        "                text_use = text3.split('SHOW TYPE:')[0]\n",
        "                Show_Type_pre = text3.split('SHOW TYPE:')[1].split()[:2]\n",
        "            else:\n",
        "                text_use = text3\n",
        "                Show_Type_pre = text3\n",
        "            \n",
        "            # who knew python accepts emojis as text? Easier for the function...\n",
        "            if 'ðŸ‘¥' in text_use:\n",
        "                Show_Name = text_use.split(' ðŸ‘¥')[0].strip()\n",
        "            else:\n",
        "                Show_Name = np.NAN\n",
        "            gowords = ['Play', 'Musical', 'Special', 'Revue', 'Operetta']\n",
        "            if any(word in Show_Type_pre for word in gowords):\n",
        "                    Show_Type = ' '.join(filter(lambda x: x in gowords, Show_Type_pre))\n",
        "            else: Show_Type = np.NAN\n",
        "            if 'Theatres' in text_use:\n",
        "                Theatre = text_use.split('Theatres: ')[1].split(' (')[0]\n",
        "            else:\n",
        "                Theatre = np.NAN\n",
        "            \n",
        "            # What types of productions are valid?\n",
        "            gowords_prod_type = ['Original','original','Production','production','Revival',\n",
        "                                 'revival','Premiere','Revised']\n",
        "            if 'Production Type:' in text_use:\n",
        "                Prod_Type_pre = text_use.split('Production Type:')[1].split()[:4]\n",
        "                if any(word in Prod_Type_pre for word in gowords_prod_type):\n",
        "                    Prod_Type = ' '.join(filter(lambda x: x in gowords_prod_type, Prod_Type_pre))\n",
        "            else:\n",
        "                Prod_Type = np.NAN    \n",
        "            if 'Run Type: ' in text_use:\n",
        "                Run_Type = text_use.split('Run Type: ')[1].split(' Market:')[0]\n",
        "            else: Run_Type = np.NAN\n",
        "            if 'Market: ' in text_use:\n",
        "                Market_pre = text_use.split('Market: ')[1][:15]\n",
        "                # there may be additional go words to add...\n",
        "                gowords = ['West','End', 'Broadway','Off','Broadway', 'Off-Broadway', 'Off-','Regional']\n",
        "                Market = ' '.join(filter(lambda x: x in gowords, Market_pre.split()))\n",
        "            else: Market = np.NAN\n",
        "            print('...')\n",
        "\n",
        "    ################ Get Theatre Address\n",
        "            try:\n",
        "                if ' Seating Chart Schedule' in text_use:\n",
        "                    Theatre_Address_pre = text_use.split('Theatre Information ')[1]\n",
        "                    if ' Seating Chart' in Theatre_Address_pre:\n",
        "                        Theatre_Address = Theatre_Address_pre.split(' Seating Chart')[0]\n",
        "                else:\n",
        "                    if ' Get Show News' in text_use:\n",
        "                        Theatre_Address_pre = text_use.split('Theatre Information ')[1]\n",
        "                        if ' Get Show News' in Theatre_Address_pre:\n",
        "                            Theatre_Address = Theatre_Address_pre.split(' Get Show News')[0]    \n",
        "                    else: Theatre_Address = Theatre_Address = text_use.split('Theatre Information ')[1][:75]\n",
        "            except:\n",
        "                Theatre_Address = np.NaN\n",
        "    \n",
        "    ################ Get Run Time        \n",
        "            if 'Running Time: ' in text_use:\n",
        "                Run_Time_pre = text_use.split('Running Time: ')[1].split(':')[0]\n",
        "                stopwords = ['Mondays', 'Tuesdays', 'Wednesdays', 'Thursdays', 'Fridays', 'Saturdays', 'Sundays']\n",
        "                Run_Time_String = ' '.join(filter(lambda x: x not in stopwords, Run_Time_pre.split()))\n",
        "                if 'intermission' in Run_Time_String:\n",
        "                    Run_Time_String = Run_Time_String.split('intermission')[0]\n",
        "            else:\n",
        "                Run_Time_String = np.NAN\n",
        "            Run_Time_Minutes = get_minutes_yes_intermission(Run_Time_String)\n",
        "            if Run_Time_Minutes ==3.0:\n",
        "                Run_Time_Minutes = 180\n",
        "            if Run_Time_Minutes ==2.0:\n",
        "                Run_Time_Minutes = 120\n",
        "            if Run_Time_Minutes ==1.0:\n",
        "                Run_Time_Minutes = 60\n",
        "            \n",
        "    ################ Get Intermission\n",
        "            if 'Intermissions: ' in text_use:\n",
        "                Intermission = text_use.split('Intermissions: ')[1][:1]\n",
        "                if 'O' in Intermission:\n",
        "                    Intermission = np.NAN \n",
        "            else:\n",
        "                Intermission = np.NAN \n",
        "                \n",
        "    ################ Get Opening Date \n",
        "            regex = r'(((January)|(February)|(March)|(April)|(May)|(June)|(July)|(August)|(September)|(October)|(November)|( November)|(December))((\\d\\d,\\s)|(\\d\\d,)|(\\s\\d\\d,\\s)|(\\s\\d\\d,))((\\d\\d\\d\\d)|(\\d\\d\\/\\d\\d\\/\\d\\d\\d\\d)))'\n",
        "                    \n",
        "            try:\n",
        "                if 'Previews: ' in text_use:\n",
        "                    pre1 = text_use.split('Previews: ')[1]\n",
        "                    if 'unknown' not in pre1[:10]:\n",
        "                        Date_Previews = re.match(regex,pre1).group(0)\n",
        "                    else:\n",
        "                        Date_Previews = np.NAN\n",
        "            except:\n",
        "                Date_Previews = np.NAN\n",
        "            if 'Opening: ' in text_use:\n",
        "                pre2 = text_use.split('Opening: ')[1]\n",
        "                if 'unknown' not in pre2.split()[:2]:\n",
        "                    Date_Open = re.match(regex,pre2).group(0)\n",
        "            else:\n",
        "                Date_Open = np.NAN\n",
        "    \n",
        "            if 'Closing: ' in text_use:\n",
        "                pre3 = text_use.split('Closing: ')[1]\n",
        "                if 'unknown' not in pre3.split()[:2]:\n",
        "                    Date_Close = re.match(regex,pre3).group(0)\n",
        "            else:\n",
        "                Date_Close = np.NAN\n",
        "        #    #months = ['January','February','March','April','May','June','July','August','September','October','November','December']   \n",
        "        #if any(match.group() for match in re.finditer(r\"\\bmonths[\\w]*\", Date)):\n",
        "\n",
        "            # compile as a dictionary\n",
        "            silver_dictionary = {'Show_Name':Show_Name,'Show_Type': Show_Type,'Theatre':Theatre,\n",
        "                                'Theatre_Address':Theatre_Address, 'Prod_Type':Prod_Type,\n",
        "                                'Run_Type':Run_Type,'Market':Market,'Intermission':Intermission, \n",
        "                                'Run_Time_String': Run_Time_String, 'Run_Time_Minutes':Run_Time_Minutes,\n",
        "                                 'Date_Previews':Date_Previews, 'Date_Open':Date_Open, 'Date_Close': Date_Close}\n",
        "            \n",
        "            # append list of dictionaries\n",
        "            dfs_silver_list.append(silver_dictionary)\n",
        "            print('\\t%d line has been scraped' %n)\n",
        "        \n",
        "        # What happens if no internet?\n",
        "        except urllib.error.URLError as err:\n",
        "            cprint('\\t\\t...! ...! ...! ...   N O   I N T E R N E T   for  line %d' %n,\n",
        "                   'red', attrs=['bold'], file=sys.stderr)\n",
        "\n",
        "        # What happens if manually interupted?\n",
        "        except (KeyboardInterrupt,SystemExit):\n",
        "            cprint('\\n\\t\\tScript was interupted by a human for line %d' %n,\n",
        "                   'red', 'on_blue',attrs=['bold'], file=sys.stderr)\n",
        "        \n",
        "        # What happens if machine rejects line?    \n",
        "        except:\n",
        "            cprint('\\t\\t\\tLine %d could not be processed' %n,'red', attrs=['bold'], file=sys.stderr)\n",
        "            lost_rows = lost_rows+1\n",
        "            pass\n",
        "        \n",
        "        # Go onto next line.\n",
        "        n = n+1\n",
        "        # Update Progress Bar\n",
        "    \n",
        "    # How long did it take the function to process?\n",
        "    end = time.time()\n",
        "    total_minutes= ((end - start)/60)\n",
        "    seconds_per_line = ((end - start)/n)\n",
        "    print('\\nFunction has run through lines 0 - %d!\\n' %n,'Function took total of %0.2f minutes.\\n' %total_minutes,\n",
        "         '\\tThat\\'s %0.3f \\tseconds per 1 lines.\\n' %seconds_per_line,\n",
        "         '\\tThat\\'s %0.3f \\tminutes per 1,000 lines.'%(seconds_per_line*(1000/60)))\n",
        "    cprint('\\nA total of %d rows were lost.' %lost_rows, 'white','on_red')\n",
        "    \n",
        "    # Here's your data.\n",
        "    silver_data = pd.DataFrame(dfs_silver_list)\n",
        "    return silver_data\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWS7zmcnPgiO",
        "colab_type": "text"
      },
      "source": [
        "### Apply function in 3 stages\n",
        "_Saves you a big headache if internet goes out for a portion or if any other interuptions are necessary*\n",
        "*Of note, **function took YB a total of 5.5 hours for all three segments.**_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11eWQd-fPgiP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "part0 = get_silver_data(show_links_nested[0][:5000])\n",
        "today = datetime.date.today().strftime('%m-%d-%Y') \n",
        "part0.to_csv('broadway_silver_data_p0 {}.csv'.format(today))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH0brfRyPgib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "part1 = get_silver_data(show_links_nested[0][5000:10000])\n",
        "today = datetime.date.today().strftime('%m-%d-%Y') \n",
        "part1.to_csv('broadway_silver_data_p1 {}.csv'.format(today))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGcNVrBhPgim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "part2 = get_silver_data(show_links_nested[0][10000:])\n",
        "today = datetime.date.today().strftime('%m-%d-%Y') \n",
        "part2.to_csv('broadway_silver_data_p2 {}.csv'.format(today))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHySTyEEPgit",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "broadway_silver_data = pd.concat([part0, part1, part2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDCc7tvWPgiv",
        "colab_type": "text"
      },
      "source": [
        "**Clean the data:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f-qDGhlPgiw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols = ['Show_Name','Run_Type','Prod_Type','Market','Theatre','Show_Type','Theatre_Address']\n",
        "for col in broadway_silver_data:\n",
        "    if col in cols:\n",
        "        broadway_silver_data[col] = broadway_silver_data[col].astype('category')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSzh8MLCPgi0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "date_cols = ['Date_Close','Date_Open', 'Date_Previews'] \n",
        "for col in broadway_silver_data:\n",
        "    if col in date_cols:\n",
        "        broadway_silver_data[col]  = pd.to_datetime(broadway_silver_data[col])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjKi9q-zPgi4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "today = datetime.date.today().strftime('%m-%d-%Y') \n",
        "broadway_silver_data.to_csv('broadway_silver_data_MAIN {}.csv'.format(today))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHrOS8JaPgi8",
        "colab_type": "text"
      },
      "source": [
        "## You have the data!\n",
        "\n",
        "    broadway_silver_data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjCdjnk0Pgi9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "broadway_silver_data.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clsu-vWNPgjB",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "   >  \n",
        "*** \n",
        "     \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL7GKKxwP5SR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}